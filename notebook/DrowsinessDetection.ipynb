{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292e10ef",
   "metadata": {},
   "source": [
    "# Driver Fatigue Detection using CNN\n",
    "\n",
    "Implemented a Convolutional Neural Network (CNN) to classify eyes as either open or closed, also employed facial recognition techniques to identify eye coordinates in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2eb1a",
   "metadata": {},
   "source": [
    "\n",
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow scikit-learn opencv-python numpy matplotlib face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af27218",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load images for training\n",
    "\n",
    "The `load_eye_images` function is employed to read images from a target folder, resize them to a consistent size (80x80 pixels), and assign labels based on the provided binary flag for eye state (0 for open, 1 for closed).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eye_images(source_path, eye_state=0):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        list: List of eye image data with corresponding labels.\n",
    "    \"\"\"\n",
    "    image_count = 0\n",
    "    error_count = 0\n",
    "    eye_images = []\n",
    "\n",
    "    for filename in os.listdir(source_path):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(source_path, filename))\n",
    "            img = cv2.resize(img, (80, 80))\n",
    "            eye_images.append([img, eye_state])\n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            print(f'Error Count: {error_count}, Exception: {e}')\n",
    "            continue\n",
    "\n",
    "        image_count += 1\n",
    "        if image_count % 500 == 0:\n",
    "            print(f'Successful Image Import Count: {image_count}')\n",
    "\n",
    "    return eye_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4ad2c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Prepare the data for training\n",
    "\n",
    "Now, we need to organize and prepare the image data for model training. Images from folders representing open and closed eyes are loaded using the `load_eye_images` function. The data is then converted into NumPy arrays, normalized, and split into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e0230",
   "metadata": {},
   "source": [
    "### Eye open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf10705",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_eye_folder = \"../train/OpenEye\"\n",
    "open_eye_data = load_eye_images(open_eye_folder, eye_state=0)\n",
    "\n",
    "# sample\n",
    "img, label = open_eye_data[20]\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee3fff",
   "metadata": {},
   "source": [
    "### Eye closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62436f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_eye_folder = \"../train/ClosedEye\"\n",
    "closed_eye_data = load_eye_images(closed_eye_folder, eye_state=1)\n",
    "\n",
    "# sample\n",
    "img, label = closed_eye_data[10]\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_data = closed_eye_data + open_eye_data\n",
    "\n",
    "X = [] \n",
    "y = [] \n",
    "for features, label in eye_data: \n",
    "     X.append(features)\n",
    "     y.append(label)\n",
    "\n",
    "# Prepare data\n",
    "X = np.array(X).reshape(-1, 80, 80, 3) / 255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3451263",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Build a Convolutional Neural Network (CNN) model\n",
    "\n",
    "We need to build a Convolutional Neural Network (CNN) Model for drowsiness detection. The model consists of convolutional layers, max-pooling layers, and dense layers. It is compiled using the Adam optimizer and binary crossentropy loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(80, 80, 3)))\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC(curve='PR')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b189cf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Model Training and Evaluation with Accuracy Plotting\n",
    "\n",
    "The fit method is used to train the model with specified batch size, validation data, and number of epochs. The evaluate method calculates the loss and specified metrics on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5383bbc",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(X_train, y_train, batch_size=800, validation_data=(X_test, y_test), epochs=24, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b69eb",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc52187",
   "metadata": {},
   "source": [
    "### Plot the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['auc']\n",
    "validation_accuracy = history.history['val_auc']\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbee450",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2822b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('drowsiness_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76098017",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Alert system\n",
    "\n",
    "Frames from the webcam are processed in real-time, and the model predicts the state of the eyes. The loop also handles visual feedback and alerts based on the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f7b60",
   "metadata": {},
   "source": [
    "\n",
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faff2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = keras.models.load_model('drowsiness_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78335c3",
   "metadata": {},
   "source": [
    "\n",
    "### Extract eye region for prediction\n",
    "\n",
    "The eyes are cropped from a webcam frame. It utilizes the `face_recognition` library to detect facial features and accurately crop the eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c200d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "def extract_eye_region_for_prediction(frame):\n",
    "\n",
    "    # Detect facial landmarks\n",
    "    facial_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "\n",
    "    if not facial_landmarks_list:\n",
    "        return\n",
    "\n",
    "    # Get left and right eye coordinates\n",
    "    try:\n",
    "        left_eye_coordinates = facial_landmarks_list[0]['left_eye']\n",
    "        right_eye_coordinates = facial_landmarks_list[0]['right_eye']\n",
    "    except KeyError:\n",
    "        return\n",
    "\n",
    "    # Draw rectangles around each eye\n",
    "    for eye_coordinates in [left_eye_coordinates, right_eye_coordinates]:\n",
    "        x_max = max([x for x, y in eye_coordinates])\n",
    "        x_min = min([x for x, y in eye_coordinates])\n",
    "        y_max = max([y for x, y in eye_coordinates])\n",
    "        y_min = min([y for x, y in eye_coordinates])\n",
    "\n",
    "        # Calculate the range of x and y coordinates\n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "\n",
    "        # Ensure the full eye is captured by calculating coordinates of a square with a 50% cushion\n",
    "        if x_range > y_range:\n",
    "            right_bound = round(0.5 * x_range) + x_max\n",
    "            left_bound = x_min - round(0.5 * x_range)\n",
    "            bottom_bound = round((right_bound - left_bound - y_range) / 2) + y_max\n",
    "            top_bound = y_min - round((right_bound - left_bound - y_range) / 2)\n",
    "        else:\n",
    "            bottom_bound = round(0.5 * y_range) + y_max\n",
    "            top_bound = y_min - round(0.5 * y_range)\n",
    "            right_bound = round((bottom_bound - top_bound - x_range) / 2) + x_max\n",
    "            left_bound = x_min - round((bottom_bound - top_bound - x_range) / 2)\n",
    "\n",
    "        # Draw rectangle around the eye\n",
    "        cv2.rectangle(frame, (left_bound, top_bound), (right_bound, bottom_bound), (255, 0, 0), 2)\n",
    "\n",
    "    # Crop the image according to the determined coordinates\n",
    "    cropped_eye_region = frame[top_bound:bottom_bound + 1, left_bound:right_bound + 1]\n",
    "\n",
    "    # Resize the cropped image to 80x80 pixels\n",
    "    resized_cropped_eye_region = cv2.resize(cropped_eye_region, (80, 80))\n",
    "\n",
    "    # Reshape the image for model prediction\n",
    "    image_for_prediction = resized_cropped_eye_region.reshape(-1, 80, 80, 3)\n",
    "\n",
    "    return image_for_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc310336",
   "metadata": {},
   "source": [
    "### Initialize the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise IOError('Cannot open webcam')\n",
    "\n",
    "    return cap, w, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe300fe",
   "metadata": {},
   "source": [
    "\n",
    "### Run drowsiness detection\n",
    "\n",
    "It uses computer vision to detect drowsiness from a webcam feed. It continuously captures and processes frames, extracting the eye region for analysis. A pre-trained model predicts eye states, triggering a visual alert for prolonged eye closure, indicating potential drowsiness. (*App can be closed by pressing 'esc'*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam\n",
    "webcam, width, height = initialize_webcam()\n",
    "\n",
    "# Initialize counters\n",
    "frame_count = 0\n",
    "blink_counter = 0\n",
    "\n",
    "# Run a continuous loop while the webcam is active\n",
    "while True:\n",
    "    # Capture frames from the webcam\n",
    "    ret, frame = webcam.read()\n",
    "\n",
    "    # Use only every other frame to manage speed and memory usage\n",
    "    if frame_count == 0:\n",
    "        frame_count += 1\n",
    "        pass\n",
    "    else:\n",
    "        frame_count = 0\n",
    "        continue\n",
    "\n",
    "    # Process the frame to get the eye for prediction\n",
    "    eye_image = extract_eye_region_for_prediction(frame)\n",
    "    try:\n",
    "        eye_image = eye_image / 255.0\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # Get prediction from the trained model\n",
    "    prediction = trained_model.predict(eye_image)\n",
    "\n",
    "    # Display status based on the prediction (\"Open Eyes\" or \"Closed Eyes\")\n",
    "    if prediction < 0.5:\n",
    "        blink_counter = 0\n",
    "        status = 'Open'\n",
    "        \n",
    "    else:\n",
    "        blink_counter += 1\n",
    "        status = 'Closed'\n",
    "\n",
    "        # If the blink counter exceeds 2, show an alert for drowsiness\n",
    "        if blink_counter > 2:\n",
    "            # Show alert message on Screen\n",
    "            cv2.rectangle(frame, (round(width / 2) - 160, round(height) - 200), (round(width / 2) + 175, round(height) - 120), (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"Blink, Don't Sleep!\", (round(width / 2) - 136, round(height) - 146), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "            cv2.imshow('Drowsiness Detection', frame)\n",
    "            k = cv2.waitKey(1)\n",
    "            blink_counter = 1\n",
    "            continue\n",
    "\n",
    "    # Show prediction on Screen\n",
    "    cv2.putText(frame, f'{prediction}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    # Show status (Open or Closed on Screen)\n",
    "    cv2.putText(frame, 'Status: ' + status, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Display the processed frame\n",
    "    cv2.imshow('Drowsiness Detection', frame)\n",
    "    \n",
    "    # Exit the loop on pressing the 'Esc' key\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
